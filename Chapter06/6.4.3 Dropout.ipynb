{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b5b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3236464682892057\n",
      "=== epoch:1, train acc:0.10666666666666667, test acc:0.0942 ===\n",
      "train loss:2.305687964923782\n",
      "train loss:2.3222072990733382\n",
      "train loss:2.29363574194059\n",
      "=== epoch:2, train acc:0.10666666666666667, test acc:0.0956 ===\n",
      "train loss:2.3040637645285726\n",
      "train loss:2.3005729681251252\n",
      "train loss:2.312752824157238\n",
      "=== epoch:3, train acc:0.10666666666666667, test acc:0.0973 ===\n",
      "train loss:2.27613278975783\n",
      "train loss:2.3015415056386814\n",
      "train loss:2.3111323587571526\n",
      "=== epoch:4, train acc:0.10666666666666667, test acc:0.0984 ===\n",
      "train loss:2.3207788233191726\n",
      "train loss:2.2900059014804377\n",
      "train loss:2.287625892398608\n",
      "=== epoch:5, train acc:0.11333333333333333, test acc:0.0988 ===\n",
      "train loss:2.3228593557529296\n",
      "train loss:2.3087722145962277\n",
      "train loss:2.289455259743465\n",
      "=== epoch:6, train acc:0.11333333333333333, test acc:0.1006 ===\n",
      "train loss:2.2922382742889647\n",
      "train loss:2.310839496056384\n",
      "train loss:2.305258643262885\n",
      "=== epoch:7, train acc:0.11333333333333333, test acc:0.1006 ===\n",
      "train loss:2.303919538619371\n",
      "train loss:2.30383054805133\n",
      "train loss:2.291467978809007\n",
      "=== epoch:8, train acc:0.11666666666666667, test acc:0.1034 ===\n",
      "train loss:2.289792326566763\n",
      "train loss:2.299703649327819\n",
      "train loss:2.274363986783832\n",
      "=== epoch:9, train acc:0.11, test acc:0.1023 ===\n",
      "train loss:2.2736894851989944\n",
      "train loss:2.303834824669256\n",
      "train loss:2.2816084994176755\n",
      "=== epoch:10, train acc:0.10666666666666667, test acc:0.107 ===\n",
      "train loss:2.294708937583973\n",
      "train loss:2.2840078582284624\n",
      "train loss:2.2903457403264373\n",
      "=== epoch:11, train acc:0.11333333333333333, test acc:0.1084 ===\n",
      "train loss:2.2981363813437183\n",
      "train loss:2.2774822261134196\n",
      "train loss:2.2974004513536626\n",
      "=== epoch:12, train acc:0.11333333333333333, test acc:0.11 ===\n",
      "train loss:2.2914647935044012\n",
      "train loss:2.2853516032477343\n",
      "train loss:2.280475955269758\n",
      "=== epoch:13, train acc:0.11666666666666667, test acc:0.1115 ===\n",
      "train loss:2.284728916051406\n",
      "train loss:2.2849994210644704\n",
      "train loss:2.287583896120879\n",
      "=== epoch:14, train acc:0.12, test acc:0.1139 ===\n",
      "train loss:2.2932670346668393\n",
      "train loss:2.2994673557697087\n",
      "train loss:2.293054829150767\n",
      "=== epoch:15, train acc:0.12, test acc:0.115 ===\n",
      "train loss:2.2825288032587245\n",
      "train loss:2.2815953640248856\n",
      "train loss:2.279301546058793\n",
      "=== epoch:16, train acc:0.13, test acc:0.1157 ===\n",
      "train loss:2.279952269127407\n",
      "train loss:2.2717533923741255\n",
      "train loss:2.2799443853718313\n",
      "=== epoch:17, train acc:0.13, test acc:0.1174 ===\n",
      "train loss:2.28633448896284\n",
      "train loss:2.2985860790918142\n",
      "train loss:2.2782631669187676\n",
      "=== epoch:18, train acc:0.13, test acc:0.1177 ===\n",
      "train loss:2.2700146952385287\n",
      "train loss:2.2802152745362094\n",
      "train loss:2.2857912907193865\n",
      "=== epoch:19, train acc:0.13, test acc:0.1184 ===\n",
      "train loss:2.2826883233227897\n",
      "train loss:2.2766661604191483\n",
      "train loss:2.278673141840523\n",
      "=== epoch:20, train acc:0.13, test acc:0.1186 ===\n",
      "train loss:2.3033569430154173\n",
      "train loss:2.273206561670888\n",
      "train loss:2.2496279749514354\n",
      "=== epoch:21, train acc:0.13333333333333333, test acc:0.1226 ===\n",
      "train loss:2.28239190108901\n",
      "train loss:2.27058422494996\n",
      "train loss:2.2859996237515294\n",
      "=== epoch:22, train acc:0.13333333333333333, test acc:0.1245 ===\n",
      "train loss:2.2813888062221683\n",
      "train loss:2.286358270506332\n",
      "train loss:2.2719695854591584\n",
      "=== epoch:23, train acc:0.13666666666666666, test acc:0.127 ===\n",
      "train loss:2.2682886670457942\n",
      "train loss:2.2709782090617727\n",
      "train loss:2.264690782206369\n",
      "=== epoch:24, train acc:0.14, test acc:0.1275 ===\n",
      "train loss:2.252513508493613\n",
      "train loss:2.3058133221985178\n",
      "train loss:2.2729674522061463\n",
      "=== epoch:25, train acc:0.14, test acc:0.1293 ===\n",
      "train loss:2.2765266405838975\n",
      "train loss:2.296555305211136\n",
      "train loss:2.2695985936008807\n",
      "=== epoch:26, train acc:0.15333333333333332, test acc:0.1329 ===\n",
      "train loss:2.26994307431726\n",
      "train loss:2.2842068200659416\n",
      "train loss:2.2859470272349682\n",
      "=== epoch:27, train acc:0.16, test acc:0.1373 ===\n",
      "train loss:2.2833477878136126\n",
      "train loss:2.2559066071348863\n",
      "train loss:2.288331799798956\n",
      "=== epoch:28, train acc:0.17, test acc:0.1418 ===\n",
      "train loss:2.27049853260642\n",
      "train loss:2.273115036828234\n",
      "train loss:2.2745266072274792\n",
      "=== epoch:29, train acc:0.17666666666666667, test acc:0.1467 ===\n",
      "train loss:2.2701670102334863\n",
      "train loss:2.2709849737864136\n",
      "train loss:2.2606346131505224\n",
      "=== epoch:30, train acc:0.17333333333333334, test acc:0.1477 ===\n",
      "train loss:2.283781769871336\n",
      "train loss:2.269152628150295\n",
      "train loss:2.264985680877264\n",
      "=== epoch:31, train acc:0.18333333333333332, test acc:0.1501 ===\n",
      "train loss:2.2645825418198218\n",
      "train loss:2.2729257110819994\n",
      "train loss:2.268322843252328\n",
      "=== epoch:32, train acc:0.19333333333333333, test acc:0.1538 ===\n",
      "train loss:2.244978133838994\n",
      "train loss:2.263277317979768\n",
      "train loss:2.2624398182184535\n",
      "=== epoch:33, train acc:0.19666666666666666, test acc:0.1567 ===\n",
      "train loss:2.282889692904813\n",
      "train loss:2.2633422316422487\n",
      "train loss:2.2555237103462966\n",
      "=== epoch:34, train acc:0.20333333333333334, test acc:0.1605 ===\n",
      "train loss:2.2534135409363505\n",
      "train loss:2.267515299450866\n",
      "train loss:2.2789497698565087\n",
      "=== epoch:35, train acc:0.20333333333333334, test acc:0.164 ===\n",
      "train loss:2.254293944693605\n",
      "train loss:2.275330431393331\n",
      "train loss:2.274562101337486\n",
      "=== epoch:36, train acc:0.20666666666666667, test acc:0.1701 ===\n",
      "train loss:2.273176925177046\n",
      "train loss:2.2718044168755207\n",
      "train loss:2.252059213422047\n",
      "=== epoch:37, train acc:0.21333333333333335, test acc:0.1735 ===\n",
      "train loss:2.26618837032275\n",
      "train loss:2.2640499692996503\n",
      "train loss:2.266942497954088\n",
      "=== epoch:38, train acc:0.21666666666666667, test acc:0.1787 ===\n",
      "train loss:2.257674692253542\n",
      "train loss:2.2627643848405086\n",
      "train loss:2.249035303327283\n",
      "=== epoch:39, train acc:0.21666666666666667, test acc:0.1772 ===\n",
      "train loss:2.2716472297667014\n",
      "train loss:2.250254854627926\n",
      "train loss:2.259569538655653\n",
      "=== epoch:40, train acc:0.22333333333333333, test acc:0.1823 ===\n",
      "train loss:2.2641587931337157\n",
      "train loss:2.2665129103345043\n",
      "train loss:2.2524582130932482\n",
      "=== epoch:41, train acc:0.23, test acc:0.186 ===\n",
      "train loss:2.2445900456137426\n",
      "train loss:2.2782595025978383\n",
      "train loss:2.2629835311124955\n",
      "=== epoch:42, train acc:0.24, test acc:0.189 ===\n",
      "train loss:2.259477844905303\n",
      "train loss:2.2461861408004293\n",
      "train loss:2.25313816080196\n",
      "=== epoch:43, train acc:0.23666666666666666, test acc:0.1892 ===\n",
      "train loss:2.252461160806641\n",
      "train loss:2.254391508494763\n",
      "train loss:2.2537851464018965\n",
      "=== epoch:44, train acc:0.23666666666666666, test acc:0.1885 ===\n",
      "train loss:2.251313353874164\n",
      "train loss:2.2459486918597413\n",
      "train loss:2.256736953081257\n",
      "=== epoch:45, train acc:0.23666666666666666, test acc:0.1889 ===\n",
      "train loss:2.2430458569223855\n",
      "train loss:2.240808726094842\n",
      "train loss:2.262768840155648\n",
      "=== epoch:46, train acc:0.23666666666666666, test acc:0.1922 ===\n",
      "train loss:2.258259669490578\n",
      "train loss:2.250360424979546\n",
      "train loss:2.231897237370321\n",
      "=== epoch:47, train acc:0.24, test acc:0.1936 ===\n",
      "train loss:2.255952476007836\n",
      "train loss:2.241101156930019\n",
      "train loss:2.251404602812358\n",
      "=== epoch:48, train acc:0.23666666666666666, test acc:0.1983 ===\n",
      "train loss:2.257057594183605\n",
      "train loss:2.244258469051494\n",
      "train loss:2.2541859702952083\n",
      "=== epoch:49, train acc:0.24333333333333335, test acc:0.2027 ===\n",
      "train loss:2.2397852483958336\n",
      "train loss:2.2467466815115267\n",
      "train loss:2.2507620075377885\n",
      "=== epoch:50, train acc:0.24666666666666667, test acc:0.2069 ===\n",
      "train loss:2.2617575118593845\n",
      "train loss:2.258784857845794\n",
      "train loss:2.247862287322586\n",
      "=== epoch:51, train acc:0.24333333333333335, test acc:0.2082 ===\n",
      "train loss:2.2446674087380916\n",
      "train loss:2.248115635335555\n",
      "train loss:2.2512552607433736\n",
      "=== epoch:52, train acc:0.24333333333333335, test acc:0.2107 ===\n",
      "train loss:2.229990313186332\n",
      "train loss:2.235177916173239\n",
      "train loss:2.250584798194049\n",
      "=== epoch:53, train acc:0.25333333333333335, test acc:0.2143 ===\n",
      "train loss:2.2255255366825843\n",
      "train loss:2.2260411518484915\n",
      "train loss:2.256789125938438\n",
      "=== epoch:54, train acc:0.26, test acc:0.2193 ===\n",
      "train loss:2.2464447881226937\n",
      "train loss:2.2419155934800203\n",
      "train loss:2.2397420652296756\n",
      "=== epoch:55, train acc:0.2633333333333333, test acc:0.2219 ===\n",
      "train loss:2.2369291088459615\n",
      "train loss:2.226385031307398\n",
      "train loss:2.243691567818164\n",
      "=== epoch:56, train acc:0.26, test acc:0.2215 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.24903511825588\n",
      "train loss:2.234169036089939\n",
      "train loss:2.2376697206334386\n",
      "=== epoch:57, train acc:0.2633333333333333, test acc:0.2221 ===\n",
      "train loss:2.2286442886758553\n",
      "train loss:2.2452846545475174\n",
      "train loss:2.2324530719971474\n",
      "=== epoch:58, train acc:0.2633333333333333, test acc:0.2246 ===\n",
      "train loss:2.240529865685644\n",
      "train loss:2.236945309191574\n",
      "train loss:2.2266525376963626\n",
      "=== epoch:59, train acc:0.2633333333333333, test acc:0.2253 ===\n",
      "train loss:2.2381975729128616\n",
      "train loss:2.2322576924699633\n",
      "train loss:2.2279772543481533\n",
      "=== epoch:60, train acc:0.27, test acc:0.2286 ===\n",
      "train loss:2.2270076367380445\n",
      "train loss:2.240560769118829\n",
      "train loss:2.260215443507924\n",
      "=== epoch:61, train acc:0.27666666666666667, test acc:0.235 ===\n",
      "train loss:2.238271178139534\n",
      "train loss:2.211937928069485\n",
      "train loss:2.2287116333456374\n",
      "=== epoch:62, train acc:0.2833333333333333, test acc:0.237 ===\n",
      "train loss:2.2183475199416725\n",
      "train loss:2.2299850995096295\n",
      "train loss:2.2476077827003875\n",
      "=== epoch:63, train acc:0.2866666666666667, test acc:0.2403 ===\n",
      "train loss:2.2271817692956084\n",
      "train loss:2.255587964790364\n",
      "train loss:2.2309168958339622\n",
      "=== epoch:64, train acc:0.29, test acc:0.2422 ===\n",
      "train loss:2.2122598322717284\n",
      "train loss:2.2094140152036705\n",
      "train loss:2.2047187026974444\n",
      "=== epoch:65, train acc:0.2866666666666667, test acc:0.2377 ===\n",
      "train loss:2.235221623299827\n",
      "train loss:2.239904527489472\n",
      "train loss:2.2183068548267157\n",
      "=== epoch:66, train acc:0.2866666666666667, test acc:0.238 ===\n",
      "train loss:2.229594040170131\n",
      "train loss:2.244687605026115\n",
      "train loss:2.2358197410440015\n",
      "=== epoch:67, train acc:0.2866666666666667, test acc:0.2414 ===\n",
      "train loss:2.2261403641517727\n",
      "train loss:2.237400180232809\n",
      "train loss:2.248067326575693\n",
      "=== epoch:68, train acc:0.29, test acc:0.242 ===\n",
      "train loss:2.231591562683551\n",
      "train loss:2.2160301507891655\n",
      "train loss:2.2430041651572963\n",
      "=== epoch:69, train acc:0.2866666666666667, test acc:0.2448 ===\n",
      "train loss:2.2270137664579166\n",
      "train loss:2.224006911507618\n",
      "train loss:2.207341147054441\n",
      "=== epoch:70, train acc:0.2866666666666667, test acc:0.2441 ===\n",
      "train loss:2.2283145315456965\n",
      "train loss:2.221964479950892\n",
      "train loss:2.202782319767578\n",
      "=== epoch:71, train acc:0.2833333333333333, test acc:0.2454 ===\n",
      "train loss:2.234643224520989\n",
      "train loss:2.2041069082088116\n",
      "train loss:2.1937765522266655\n",
      "=== epoch:72, train acc:0.2833333333333333, test acc:0.2454 ===\n",
      "train loss:2.235286887415265\n",
      "train loss:2.23286625189939\n",
      "train loss:2.226043443118476\n",
      "=== epoch:73, train acc:0.2866666666666667, test acc:0.2488 ===\n",
      "train loss:2.219617577427644\n",
      "train loss:2.19268433090632\n",
      "train loss:2.2085766134159925\n",
      "=== epoch:74, train acc:0.29333333333333333, test acc:0.2505 ===\n",
      "train loss:2.207240811980235\n",
      "train loss:2.20499134043804\n",
      "train loss:2.2254579351446004\n",
      "=== epoch:75, train acc:0.29333333333333333, test acc:0.2513 ===\n",
      "train loss:2.2274492784915965\n",
      "train loss:2.2018802112317344\n",
      "train loss:2.204922402384517\n",
      "=== epoch:76, train acc:0.2866666666666667, test acc:0.2525 ===\n",
      "train loss:2.2048155534405662\n",
      "train loss:2.2296018935240554\n",
      "train loss:2.230241795654856\n",
      "=== epoch:77, train acc:0.2866666666666667, test acc:0.2536 ===\n",
      "train loss:2.2203083289947143\n",
      "train loss:2.2195796192723583\n",
      "train loss:2.195529681449247\n",
      "=== epoch:78, train acc:0.29333333333333333, test acc:0.2528 ===\n",
      "train loss:2.199576208325193\n",
      "train loss:2.202504849291911\n",
      "train loss:2.1828864424071206\n",
      "=== epoch:79, train acc:0.29333333333333333, test acc:0.2492 ===\n",
      "train loss:2.188622275130496\n",
      "train loss:2.204081198109209\n",
      "train loss:2.200197114665211\n",
      "=== epoch:80, train acc:0.29, test acc:0.2446 ===\n",
      "train loss:2.201410545261495\n",
      "train loss:2.2063825564820085\n",
      "train loss:2.218120842474278\n",
      "=== epoch:81, train acc:0.2866666666666667, test acc:0.2436 ===\n",
      "train loss:2.2036570084570872\n",
      "train loss:2.1889972460866804\n",
      "train loss:2.2124239115898723\n",
      "=== epoch:82, train acc:0.2833333333333333, test acc:0.2406 ===\n",
      "train loss:2.1838950597545446\n",
      "train loss:2.2151599769291175\n",
      "train loss:2.2161514766897095\n",
      "=== epoch:83, train acc:0.2833333333333333, test acc:0.2376 ===\n",
      "train loss:2.18942868896216\n",
      "train loss:2.2048523144321583\n",
      "train loss:2.200862214939186\n",
      "=== epoch:84, train acc:0.29, test acc:0.2446 ===\n",
      "train loss:2.2158161026943137\n",
      "train loss:2.1765629902623638\n",
      "train loss:2.2094793555912813\n",
      "=== epoch:85, train acc:0.29333333333333333, test acc:0.2488 ===\n",
      "train loss:2.1924581257034053\n",
      "train loss:2.2000537368302333\n",
      "train loss:2.204974229368689\n",
      "=== epoch:86, train acc:0.29333333333333333, test acc:0.2515 ===\n",
      "train loss:2.2042480947306196\n",
      "train loss:2.1947495182072956\n",
      "train loss:2.19158998823014\n",
      "=== epoch:87, train acc:0.29333333333333333, test acc:0.2545 ===\n",
      "train loss:2.203119122475686\n",
      "train loss:2.1918396896446417\n",
      "train loss:2.180391250823902\n",
      "=== epoch:88, train acc:0.2966666666666667, test acc:0.2566 ===\n",
      "train loss:2.1943480519493055\n",
      "train loss:2.1974988302959826\n",
      "train loss:2.17662320723489\n",
      "=== epoch:89, train acc:0.29, test acc:0.2574 ===\n",
      "train loss:2.1943729113199884\n",
      "train loss:2.1808186685985516\n",
      "train loss:2.2085634059033925\n",
      "=== epoch:90, train acc:0.3, test acc:0.262 ===\n",
      "train loss:2.198610032444215\n",
      "train loss:2.167150117730136\n",
      "train loss:2.1613180005289023\n",
      "=== epoch:91, train acc:0.2966666666666667, test acc:0.2543 ===\n",
      "train loss:2.1836266299376854\n",
      "train loss:2.183180620264271\n",
      "train loss:2.186558945419838\n",
      "=== epoch:92, train acc:0.29333333333333333, test acc:0.2546 ===\n",
      "train loss:2.173779962066641\n",
      "train loss:2.1763017421218205\n",
      "train loss:2.197949105438283\n",
      "=== epoch:93, train acc:0.2966666666666667, test acc:0.256 ===\n",
      "train loss:2.197322593662222\n",
      "train loss:2.187089352376897\n",
      "train loss:2.2129697928888734\n",
      "=== epoch:94, train acc:0.3, test acc:0.2625 ===\n",
      "train loss:2.1848531282810826\n",
      "train loss:2.1890838070759595\n",
      "train loss:2.1797576646653236\n",
      "=== epoch:95, train acc:0.31, test acc:0.267 ===\n",
      "train loss:2.1598257517911517\n",
      "train loss:2.175431287931773\n",
      "train loss:2.181784272310272\n",
      "=== epoch:96, train acc:0.31666666666666665, test acc:0.2723 ===\n",
      "train loss:2.1866137343992427\n",
      "train loss:2.1486394509665656\n",
      "train loss:2.1676230802467704\n",
      "=== epoch:97, train acc:0.32, test acc:0.2727 ===\n",
      "train loss:2.1521657798585982\n",
      "train loss:2.1664177346482463\n",
      "train loss:2.164262446259637\n",
      "=== epoch:98, train acc:0.32666666666666666, test acc:0.2719 ===\n",
      "train loss:2.1425862306098344\n",
      "train loss:2.19301461823726\n",
      "train loss:2.1811338152563486\n",
      "=== epoch:99, train acc:0.3333333333333333, test acc:0.2756 ===\n",
      "train loss:2.182003779359202\n",
      "train loss:2.162202103114975\n",
      "train loss:2.1552738806683784\n",
      "=== epoch:100, train acc:0.33, test acc:0.2777 ===\n",
      "train loss:2.133741176227664\n",
      "train loss:2.161615578520344\n",
      "train loss:2.1940469231108684\n",
      "=== epoch:101, train acc:0.3333333333333333, test acc:0.2823 ===\n",
      "train loss:2.1494449552112243\n",
      "train loss:2.1536152782739637\n",
      "train loss:2.184782874396783\n",
      "=== epoch:102, train acc:0.32666666666666666, test acc:0.2768 ===\n",
      "train loss:2.164817609709892\n",
      "train loss:2.1733410801234396\n",
      "train loss:2.182771366241664\n",
      "=== epoch:103, train acc:0.32, test acc:0.2764 ===\n",
      "train loss:2.162990570507567\n",
      "train loss:2.1409877559914836\n",
      "train loss:2.157692749781972\n",
      "=== epoch:104, train acc:0.3233333333333333, test acc:0.281 ===\n",
      "train loss:2.13089116110465\n",
      "train loss:2.1477969503898464\n",
      "train loss:2.1842445868124276\n",
      "=== epoch:105, train acc:0.32666666666666666, test acc:0.2826 ===\n",
      "train loss:2.1031090904104817\n",
      "train loss:2.1712567427406837\n",
      "train loss:2.1521873536660827\n",
      "=== epoch:106, train acc:0.33666666666666667, test acc:0.2817 ===\n",
      "train loss:2.110094415998485\n",
      "train loss:2.1620631480302874\n",
      "train loss:2.1217040556739515\n",
      "=== epoch:107, train acc:0.33, test acc:0.2805 ===\n",
      "train loss:2.1404342738098148\n",
      "train loss:2.1157190704776587\n",
      "train loss:2.140476310171376\n",
      "=== epoch:108, train acc:0.33, test acc:0.2789 ===\n",
      "train loss:2.1013147017583322\n",
      "train loss:2.153672117414768\n",
      "train loss:2.1276281993337505\n",
      "=== epoch:109, train acc:0.3233333333333333, test acc:0.2775 ===\n",
      "train loss:2.1363403445905313\n",
      "train loss:2.1664776765050324\n",
      "train loss:2.171496912535531\n",
      "=== epoch:110, train acc:0.3466666666666667, test acc:0.286 ===\n",
      "train loss:2.1245173729024547\n",
      "train loss:2.1270607074044436\n",
      "train loss:2.125413217986884\n",
      "=== epoch:111, train acc:0.32666666666666666, test acc:0.2827 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.103140314499743\n",
      "train loss:2.098977754513396\n",
      "train loss:2.142900965255079\n",
      "=== epoch:112, train acc:0.33, test acc:0.2761 ===\n",
      "train loss:2.1410501801573063\n",
      "train loss:2.151942826996606\n",
      "train loss:2.143836400524801\n",
      "=== epoch:113, train acc:0.33, test acc:0.2821 ===\n",
      "train loss:2.1041101110350042\n",
      "train loss:2.147566894842193\n",
      "train loss:2.1346046529631617\n",
      "=== epoch:114, train acc:0.3333333333333333, test acc:0.2804 ===\n",
      "train loss:2.101235170439859\n",
      "train loss:2.110149505586221\n",
      "train loss:2.125492814481018\n",
      "=== epoch:115, train acc:0.3333333333333333, test acc:0.2828 ===\n",
      "train loss:2.0989628985598707\n",
      "train loss:2.091657679864566\n",
      "train loss:2.13640781037462\n",
      "=== epoch:116, train acc:0.33666666666666667, test acc:0.2809 ===\n",
      "train loss:2.1235691182509133\n",
      "train loss:2.1240196304188412\n",
      "train loss:2.076329358728451\n",
      "=== epoch:117, train acc:0.33, test acc:0.2809 ===\n",
      "train loss:2.071215869026121\n",
      "train loss:2.1049090546411104\n",
      "train loss:2.1090648214737033\n",
      "=== epoch:118, train acc:0.33, test acc:0.2781 ===\n",
      "train loss:2.1230067802439256\n",
      "train loss:2.1252165330029893\n",
      "train loss:2.113183045378593\n",
      "=== epoch:119, train acc:0.3333333333333333, test acc:0.2808 ===\n",
      "train loss:2.1017265134141523\n",
      "train loss:2.1021133943649932\n",
      "train loss:2.1381399261012906\n",
      "=== epoch:120, train acc:0.33666666666666667, test acc:0.2811 ===\n",
      "train loss:2.125252659235561\n",
      "train loss:2.1112216310478593\n",
      "train loss:2.1233240949906325\n",
      "=== epoch:121, train acc:0.33666666666666667, test acc:0.2884 ===\n",
      "train loss:2.063612491617799\n",
      "train loss:2.0947248649137915\n",
      "train loss:2.137986484094911\n",
      "=== epoch:122, train acc:0.33666666666666667, test acc:0.2879 ===\n",
      "train loss:2.0660783776613463\n",
      "train loss:2.073386793272171\n",
      "train loss:2.0872922038863013\n",
      "=== epoch:123, train acc:0.33666666666666667, test acc:0.2855 ===\n",
      "train loss:2.0837171070347655\n",
      "train loss:2.083719528130237\n",
      "train loss:2.1060753771669907\n",
      "=== epoch:124, train acc:0.3433333333333333, test acc:0.2883 ===\n",
      "train loss:2.100348406432931\n",
      "train loss:2.11193438856521\n",
      "train loss:2.0729955456527125\n",
      "=== epoch:125, train acc:0.3466666666666667, test acc:0.2899 ===\n",
      "train loss:2.0607744039110365\n",
      "train loss:2.115445630076379\n",
      "train loss:2.0961053200223216\n",
      "=== epoch:126, train acc:0.35, test acc:0.2904 ===\n",
      "train loss:2.070657194958329\n",
      "train loss:2.1104282261677643\n",
      "train loss:2.0435933100689105\n",
      "=== epoch:127, train acc:0.3433333333333333, test acc:0.2917 ===\n",
      "train loss:2.0900741678335235\n",
      "train loss:2.0862743451045005\n",
      "train loss:2.0272744284203656\n",
      "=== epoch:128, train acc:0.3566666666666667, test acc:0.2944 ===\n",
      "train loss:2.0524010639125048\n",
      "train loss:2.1174790645901513\n",
      "train loss:2.0757079492628536\n",
      "=== epoch:129, train acc:0.3566666666666667, test acc:0.2946 ===\n",
      "train loss:2.0642273546891206\n",
      "train loss:2.1367433368478106\n",
      "train loss:2.0970935432350704\n",
      "=== epoch:130, train acc:0.36, test acc:0.3005 ===\n",
      "train loss:2.063880871991415\n",
      "train loss:2.06111090748251\n",
      "train loss:2.0174987681445065\n",
      "=== epoch:131, train acc:0.36, test acc:0.302 ===\n",
      "train loss:2.086555145967024\n",
      "train loss:2.053936407870209\n",
      "train loss:2.072509479602805\n",
      "=== epoch:132, train acc:0.36, test acc:0.3049 ===\n",
      "train loss:2.0307114504216006\n",
      "train loss:2.060575350654086\n",
      "train loss:2.009314007927665\n",
      "=== epoch:133, train acc:0.3566666666666667, test acc:0.3032 ===\n",
      "train loss:2.0251285170967335\n",
      "train loss:2.0277838081604385\n",
      "train loss:2.077644212881648\n",
      "=== epoch:134, train acc:0.3566666666666667, test acc:0.3019 ===\n",
      "train loss:2.0040361672738825\n",
      "train loss:2.0812885584358862\n",
      "train loss:2.0636114099546665\n",
      "=== epoch:135, train acc:0.36333333333333334, test acc:0.3045 ===\n",
      "train loss:2.0787325126855656\n",
      "train loss:2.026606136059989\n",
      "train loss:2.0497070888418665\n",
      "=== epoch:136, train acc:0.38, test acc:0.3055 ===\n",
      "train loss:2.0487030085600026\n",
      "train loss:2.039670243030925\n",
      "train loss:2.0380727588500718\n",
      "=== epoch:137, train acc:0.37666666666666665, test acc:0.3108 ===\n",
      "train loss:2.0732957898690385\n",
      "train loss:2.0168591972398255\n",
      "train loss:1.9870114322998276\n",
      "=== epoch:138, train acc:0.38, test acc:0.3085 ===\n",
      "train loss:1.9906914580852595\n",
      "train loss:2.0165303014774527\n",
      "train loss:2.032425405458126\n",
      "=== epoch:139, train acc:0.39, test acc:0.3079 ===\n",
      "train loss:2.023685750657224\n",
      "train loss:1.99196198300844\n",
      "train loss:1.9929819207568231\n",
      "=== epoch:140, train acc:0.38, test acc:0.3089 ===\n",
      "train loss:2.0090818979282083\n",
      "train loss:2.0144269500401446\n",
      "train loss:1.9832044089000427\n",
      "=== epoch:141, train acc:0.38333333333333336, test acc:0.3084 ===\n",
      "train loss:2.036326307288221\n",
      "train loss:1.989333873975245\n",
      "train loss:2.0136572882190165\n",
      "=== epoch:142, train acc:0.38666666666666666, test acc:0.3067 ===\n",
      "train loss:1.9736911786345\n",
      "train loss:2.064125207825029\n",
      "train loss:1.9612986161908117\n",
      "=== epoch:143, train acc:0.39, test acc:0.3065 ===\n",
      "train loss:2.009188598621134\n",
      "train loss:1.99006871747079\n",
      "train loss:1.9779196493063782\n",
      "=== epoch:144, train acc:0.4, test acc:0.3055 ===\n",
      "train loss:1.9462905571625442\n",
      "train loss:2.0492641943582672\n",
      "train loss:1.9189993157848628\n",
      "=== epoch:145, train acc:0.38666666666666666, test acc:0.3029 ===\n",
      "train loss:2.068918100887334\n",
      "train loss:2.0211637858370164\n",
      "train loss:2.0113814385468327\n",
      "=== epoch:146, train acc:0.39666666666666667, test acc:0.3072 ===\n",
      "train loss:1.9951512042095805\n",
      "train loss:2.007003928615692\n",
      "train loss:2.010504986923432\n",
      "=== epoch:147, train acc:0.4, test acc:0.3093 ===\n",
      "train loss:1.9955508079857085\n",
      "train loss:2.021836221964825\n",
      "train loss:1.8748765133077296\n",
      "=== epoch:148, train acc:0.3933333333333333, test acc:0.3061 ===\n",
      "train loss:1.9396942398597665\n",
      "train loss:1.9564690892001786\n",
      "train loss:1.9582952620401193\n",
      "=== epoch:149, train acc:0.4, test acc:0.3053 ===\n",
      "train loss:1.9718475496873225\n",
      "train loss:1.9906001782753797\n",
      "train loss:1.9867216866152955\n",
      "=== epoch:150, train acc:0.39666666666666667, test acc:0.3067 ===\n",
      "train loss:1.9538604543109557\n",
      "train loss:1.931785479946089\n",
      "train loss:1.9658896537928274\n",
      "=== epoch:151, train acc:0.39, test acc:0.3041 ===\n",
      "train loss:1.9871309139514597\n",
      "train loss:1.9700687161895534\n",
      "train loss:1.9464803391238457\n",
      "=== epoch:152, train acc:0.38333333333333336, test acc:0.3032 ===\n",
      "train loss:1.9943460287528458\n",
      "train loss:1.8874224461381937\n",
      "train loss:1.9868828966774805\n",
      "=== epoch:153, train acc:0.39666666666666667, test acc:0.3048 ===\n",
      "train loss:1.932462291064294\n",
      "train loss:2.0076349099796964\n",
      "train loss:1.9297853729269574\n",
      "=== epoch:154, train acc:0.4, test acc:0.3087 ===\n",
      "train loss:1.9504091532435581\n",
      "train loss:1.949287519201051\n",
      "train loss:1.9181033150420828\n",
      "=== epoch:155, train acc:0.4033333333333333, test acc:0.3105 ===\n",
      "train loss:1.9076426890421896\n",
      "train loss:1.9538279338734623\n",
      "train loss:1.889498475629987\n",
      "=== epoch:156, train acc:0.4033333333333333, test acc:0.3094 ===\n",
      "train loss:1.9723318559942127\n",
      "train loss:1.9511813344579536\n",
      "train loss:1.8914971686161162\n",
      "=== epoch:157, train acc:0.4, test acc:0.3122 ===\n",
      "train loss:1.9607012171534197\n",
      "train loss:1.8977824801945835\n",
      "train loss:1.9828038843146771\n",
      "=== epoch:158, train acc:0.38333333333333336, test acc:0.3151 ===\n",
      "train loss:1.9465127847845956\n",
      "train loss:1.8765023185371976\n",
      "train loss:1.9077701236656512\n",
      "=== epoch:159, train acc:0.38333333333333336, test acc:0.3143 ===\n",
      "train loss:1.9516918224941007\n",
      "train loss:1.9813439156729675\n",
      "train loss:1.896835161809667\n",
      "=== epoch:160, train acc:0.39, test acc:0.3173 ===\n",
      "train loss:1.8232074355220482\n",
      "train loss:1.954848595785582\n",
      "train loss:1.9221149902536545\n",
      "=== epoch:161, train acc:0.39, test acc:0.3152 ===\n",
      "train loss:1.9402342267984851\n",
      "train loss:1.8942669083584622\n",
      "train loss:1.9621748326629733\n",
      "=== epoch:162, train acc:0.39666666666666667, test acc:0.3183 ===\n",
      "train loss:1.873238700168786\n",
      "train loss:1.9103433907774134\n",
      "train loss:1.8764176127447534\n",
      "=== epoch:163, train acc:0.39, test acc:0.3176 ===\n",
      "train loss:1.8921881141552908\n",
      "train loss:1.8568318727808486\n",
      "train loss:1.8237619691815086\n",
      "=== epoch:164, train acc:0.39666666666666667, test acc:0.3148 ===\n",
      "train loss:1.9310201306335066\n",
      "train loss:1.867431180913707\n",
      "train loss:1.8944453006727686\n",
      "=== epoch:165, train acc:0.3933333333333333, test acc:0.3173 ===\n",
      "train loss:1.913589738471762\n",
      "train loss:1.9088259130409295\n",
      "train loss:1.921266239829136\n",
      "=== epoch:166, train acc:0.38666666666666666, test acc:0.3187 ===\n",
      "train loss:1.861376990579883\n",
      "train loss:1.8851904500649161\n",
      "train loss:1.9328771947596368\n",
      "=== epoch:167, train acc:0.39, test acc:0.3194 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.917907208996954\n",
      "train loss:1.800309215594647\n",
      "train loss:1.9742532325422362\n",
      "=== epoch:168, train acc:0.3933333333333333, test acc:0.3202 ===\n",
      "train loss:1.814411704105751\n",
      "train loss:1.8075322728238603\n",
      "train loss:1.9079750188738183\n",
      "=== epoch:169, train acc:0.3933333333333333, test acc:0.3223 ===\n",
      "train loss:1.8722058357122848\n",
      "train loss:1.894670605844961\n",
      "train loss:1.8724881514442302\n",
      "=== epoch:170, train acc:0.38333333333333336, test acc:0.3231 ===\n",
      "train loss:1.9098635511897215\n",
      "train loss:1.798299540214536\n",
      "train loss:1.8758816453749123\n",
      "=== epoch:171, train acc:0.39, test acc:0.324 ===\n",
      "train loss:1.8592135030829247\n",
      "train loss:1.8927801675425706\n",
      "train loss:1.8735773754593459\n",
      "=== epoch:172, train acc:0.39666666666666667, test acc:0.3272 ===\n",
      "train loss:1.8049707049427062\n",
      "train loss:1.8264545068780182\n",
      "train loss:1.8302687827293393\n",
      "=== epoch:173, train acc:0.39666666666666667, test acc:0.326 ===\n",
      "train loss:1.8702148373545355\n",
      "train loss:1.905781620256997\n",
      "train loss:1.8348525906417976\n",
      "=== epoch:174, train acc:0.3933333333333333, test acc:0.3263 ===\n",
      "train loss:1.829284947412685\n",
      "train loss:1.8548942676725895\n",
      "train loss:1.8781472938454087\n",
      "=== epoch:175, train acc:0.39666666666666667, test acc:0.33 ===\n",
      "train loss:1.801012872186661\n",
      "train loss:1.8499293003690296\n",
      "train loss:1.885629391334554\n",
      "=== epoch:176, train acc:0.3933333333333333, test acc:0.3273 ===\n",
      "train loss:1.837563739666445\n",
      "train loss:1.8156788809109454\n",
      "train loss:1.826609277579057\n",
      "=== epoch:177, train acc:0.3933333333333333, test acc:0.3263 ===\n",
      "train loss:1.860253117304164\n",
      "train loss:1.7435077667110062\n",
      "train loss:1.8569325174874864\n",
      "=== epoch:178, train acc:0.3933333333333333, test acc:0.3266 ===\n",
      "train loss:1.8531927792364598\n",
      "train loss:1.8275971417927337\n",
      "train loss:1.8138806445208746\n",
      "=== epoch:179, train acc:0.4033333333333333, test acc:0.3335 ===\n",
      "train loss:1.7908924083645195\n",
      "train loss:1.8176703439607638\n",
      "train loss:1.7009224147291548\n",
      "=== epoch:180, train acc:0.4, test acc:0.334 ===\n",
      "train loss:1.8590271467329769\n",
      "train loss:1.7774997442174816\n",
      "train loss:1.857574222229029\n",
      "=== epoch:181, train acc:0.4033333333333333, test acc:0.3382 ===\n",
      "train loss:1.7191179659024567\n",
      "train loss:1.767672250768007\n",
      "train loss:1.7845441819901762\n",
      "=== epoch:182, train acc:0.41333333333333333, test acc:0.3418 ===\n",
      "train loss:1.750061479097612\n",
      "train loss:1.7540954552931494\n",
      "train loss:1.685299389755985\n",
      "=== epoch:183, train acc:0.41333333333333333, test acc:0.3435 ===\n",
      "train loss:1.8175864893450264\n",
      "train loss:1.7207500332479921\n",
      "train loss:1.745695117041063\n",
      "=== epoch:184, train acc:0.4066666666666667, test acc:0.3429 ===\n",
      "train loss:1.7813853792847487\n",
      "train loss:1.6498676034680122\n",
      "train loss:1.8419378120446275\n",
      "=== epoch:185, train acc:0.42, test acc:0.3486 ===\n",
      "train loss:1.7033553675234148\n",
      "train loss:1.7342364608361895\n",
      "train loss:1.8391067547824838\n",
      "=== epoch:186, train acc:0.41333333333333333, test acc:0.3486 ===\n",
      "train loss:1.796624498554685\n",
      "train loss:1.7899519047609798\n",
      "train loss:1.7686625500343138\n",
      "=== epoch:187, train acc:0.42333333333333334, test acc:0.3546 ===\n",
      "train loss:1.7353666226815077\n",
      "train loss:1.7833697108052586\n",
      "train loss:1.7180497955846636\n",
      "=== epoch:188, train acc:0.4266666666666667, test acc:0.357 ===\n",
      "train loss:1.7194187382112143\n",
      "train loss:1.8185830194368733\n",
      "train loss:1.7822905840361722\n",
      "=== epoch:189, train acc:0.43, test acc:0.354 ===\n",
      "train loss:1.7496322326808447\n",
      "train loss:1.7248577994183396\n",
      "train loss:1.7078605025352231\n",
      "=== epoch:190, train acc:0.42, test acc:0.3518 ===\n",
      "train loss:1.8165333184511891\n",
      "train loss:1.7674239390255615\n",
      "train loss:1.7059252545704686\n",
      "=== epoch:191, train acc:0.4266666666666667, test acc:0.3575 ===\n",
      "train loss:1.7759360643893058\n",
      "train loss:1.622314984000146\n",
      "train loss:1.6401011261995444\n",
      "=== epoch:192, train acc:0.42, test acc:0.3549 ===\n",
      "train loss:1.6531871149972324\n",
      "train loss:1.835573142232744\n",
      "train loss:1.7615728671064272\n",
      "=== epoch:193, train acc:0.42, test acc:0.3522 ===\n",
      "train loss:1.76999177350417\n",
      "train loss:1.690914847141148\n",
      "train loss:1.7737085813228566\n",
      "=== epoch:194, train acc:0.42333333333333334, test acc:0.3574 ===\n",
      "train loss:1.7040043128528426\n",
      "train loss:1.826328034655603\n",
      "train loss:1.6559846718628577\n",
      "=== epoch:195, train acc:0.42333333333333334, test acc:0.3601 ===\n",
      "train loss:1.7927672525189744\n",
      "train loss:1.6912808207742092\n",
      "train loss:1.6949065141938453\n",
      "=== epoch:196, train acc:0.4266666666666667, test acc:0.3601 ===\n",
      "train loss:1.7557230136656268\n",
      "train loss:1.7536215518166605\n",
      "train loss:1.7258435914241437\n",
      "=== epoch:197, train acc:0.44666666666666666, test acc:0.3633 ===\n",
      "train loss:1.6449433650009353\n",
      "train loss:1.6393854926364728\n",
      "train loss:1.6765104307038095\n",
      "=== epoch:198, train acc:0.43, test acc:0.3595 ===\n",
      "train loss:1.7335519121696317\n",
      "train loss:1.710789428291517\n",
      "train loss:1.7070295031663876\n",
      "=== epoch:199, train acc:0.43333333333333335, test acc:0.3568 ===\n",
      "train loss:1.7601177337436595\n",
      "train loss:1.7413297367964757\n",
      "train loss:1.6951869776362387\n",
      "=== epoch:200, train acc:0.43666666666666665, test acc:0.3607 ===\n",
      "train loss:1.679506448586805\n",
      "train loss:1.7757277579006467\n",
      "train loss:1.730371983271333\n",
      "=== epoch:201, train acc:0.44333333333333336, test acc:0.3663 ===\n",
      "train loss:1.6880676705538549\n",
      "train loss:1.5986202659093738\n",
      "train loss:1.6683011013454427\n",
      "=== epoch:202, train acc:0.4633333333333333, test acc:0.3705 ===\n",
      "train loss:1.749322987366483\n",
      "train loss:1.6630861441806182\n",
      "train loss:1.7213503131080634\n",
      "=== epoch:203, train acc:0.4666666666666667, test acc:0.3765 ===\n",
      "train loss:1.650638985371478\n",
      "train loss:1.5966010833028408\n",
      "train loss:1.5800182836614705\n",
      "=== epoch:204, train acc:0.4666666666666667, test acc:0.3742 ===\n",
      "train loss:1.6931754822662086\n",
      "train loss:1.716932405390443\n",
      "train loss:1.6791370789581848\n",
      "=== epoch:205, train acc:0.4633333333333333, test acc:0.3729 ===\n",
      "train loss:1.732401665359277\n",
      "train loss:1.671664012553629\n",
      "train loss:1.681808211610744\n",
      "=== epoch:206, train acc:0.45, test acc:0.3705 ===\n",
      "train loss:1.6045120584846666\n",
      "train loss:1.6511869983413368\n",
      "train loss:1.61217360774355\n",
      "=== epoch:207, train acc:0.46, test acc:0.3737 ===\n",
      "train loss:1.6108972931163064\n",
      "train loss:1.5887997293032057\n",
      "train loss:1.6581368761612152\n",
      "=== epoch:208, train acc:0.45666666666666667, test acc:0.3734 ===\n",
      "train loss:1.7345829653116724\n",
      "train loss:1.704630566567115\n",
      "train loss:1.6834905652597043\n",
      "=== epoch:209, train acc:0.47, test acc:0.3878 ===\n",
      "train loss:1.640318037200017\n",
      "train loss:1.5551739289142872\n",
      "train loss:1.645510686647873\n",
      "=== epoch:210, train acc:0.48, test acc:0.3879 ===\n",
      "train loss:1.746531166695121\n",
      "train loss:1.6750727354327637\n",
      "train loss:1.7285963653576462\n",
      "=== epoch:211, train acc:0.4866666666666667, test acc:0.3933 ===\n",
      "train loss:1.5356460354132406\n",
      "train loss:1.6150745605252106\n",
      "train loss:1.6018143948502754\n",
      "=== epoch:212, train acc:0.49333333333333335, test acc:0.4012 ===\n",
      "train loss:1.5744953974398015\n",
      "train loss:1.617180609315843\n",
      "train loss:1.6739094579831808\n",
      "=== epoch:213, train acc:0.5, test acc:0.3995 ===\n",
      "train loss:1.5886841489797132\n",
      "train loss:1.6428468110416268\n",
      "train loss:1.5712590239799575\n",
      "=== epoch:214, train acc:0.5, test acc:0.4045 ===\n",
      "train loss:1.6012652409073735\n",
      "train loss:1.5590058163365927\n",
      "train loss:1.6928745680769104\n",
      "=== epoch:215, train acc:0.5166666666666667, test acc:0.4058 ===\n",
      "train loss:1.6446055966583708\n",
      "train loss:1.6995595074962273\n",
      "train loss:1.675238407162918\n",
      "=== epoch:216, train acc:0.5133333333333333, test acc:0.4052 ===\n",
      "train loss:1.5599921655292082\n",
      "train loss:1.5179583485419608\n",
      "train loss:1.570861824354833\n",
      "=== epoch:217, train acc:0.5033333333333333, test acc:0.4017 ===\n",
      "train loss:1.5979830616968402\n",
      "train loss:1.5805518493828328\n",
      "train loss:1.5226750065563621\n",
      "=== epoch:218, train acc:0.5, test acc:0.3963 ===\n",
      "train loss:1.6669353066152663\n",
      "train loss:1.6878757316003117\n",
      "train loss:1.623906119990815\n",
      "=== epoch:219, train acc:0.51, test acc:0.401 ===\n",
      "train loss:1.5366286438683527\n",
      "train loss:1.4669982281992906\n",
      "train loss:1.6312118495908376\n",
      "=== epoch:220, train acc:0.5033333333333333, test acc:0.3997 ===\n",
      "train loss:1.5111795225896174\n",
      "train loss:1.529931458681057\n",
      "train loss:1.6127746343411216\n",
      "=== epoch:221, train acc:0.5033333333333333, test acc:0.3968 ===\n",
      "train loss:1.5900157162781448\n",
      "train loss:1.6574220959693997\n",
      "train loss:1.71640031218699\n",
      "=== epoch:222, train acc:0.5033333333333333, test acc:0.398 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.4950850068241746\n",
      "train loss:1.46646208831452\n",
      "train loss:1.6279074889213163\n",
      "=== epoch:223, train acc:0.5066666666666667, test acc:0.3998 ===\n",
      "train loss:1.5524056983755887\n",
      "train loss:1.5715499503977253\n",
      "train loss:1.745707590654675\n",
      "=== epoch:224, train acc:0.5, test acc:0.4025 ===\n",
      "train loss:1.5888924148887684\n",
      "train loss:1.5528272764976598\n",
      "train loss:1.5197826435807469\n",
      "=== epoch:225, train acc:0.49666666666666665, test acc:0.4043 ===\n",
      "train loss:1.5370044973218118\n",
      "train loss:1.4567479455046388\n",
      "train loss:1.5215856104590815\n",
      "=== epoch:226, train acc:0.49333333333333335, test acc:0.4009 ===\n",
      "train loss:1.5551799648389368\n",
      "train loss:1.518995461766008\n",
      "train loss:1.5131747920159069\n",
      "=== epoch:227, train acc:0.5, test acc:0.4069 ===\n",
      "train loss:1.5358489064689187\n",
      "train loss:1.5699598753039934\n",
      "train loss:1.5285646666143113\n",
      "=== epoch:228, train acc:0.5033333333333333, test acc:0.4054 ===\n",
      "train loss:1.5077664608635055\n",
      "train loss:1.5426809529426482\n",
      "train loss:1.6599451424301057\n",
      "=== epoch:229, train acc:0.5033333333333333, test acc:0.41 ===\n",
      "train loss:1.5160178362153442\n",
      "train loss:1.5289314684764053\n",
      "train loss:1.5203453085768552\n",
      "=== epoch:230, train acc:0.5066666666666667, test acc:0.414 ===\n",
      "train loss:1.5361097980601273\n",
      "train loss:1.4945981883855928\n",
      "train loss:1.569139391084812\n",
      "=== epoch:231, train acc:0.5233333333333333, test acc:0.4212 ===\n",
      "train loss:1.4912335600821305\n",
      "train loss:1.572082549384267\n",
      "train loss:1.5568399431845554\n",
      "=== epoch:232, train acc:0.5133333333333333, test acc:0.418 ===\n",
      "train loss:1.5053692468214848\n",
      "train loss:1.5377958405350831\n",
      "train loss:1.4916898845863593\n",
      "=== epoch:233, train acc:0.5266666666666666, test acc:0.4223 ===\n",
      "train loss:1.4411463413784913\n",
      "train loss:1.470776469698076\n",
      "train loss:1.5814414100117355\n",
      "=== epoch:234, train acc:0.5333333333333333, test acc:0.4265 ===\n",
      "train loss:1.4457153589865164\n",
      "train loss:1.6205689745542782\n",
      "train loss:1.387517724122215\n",
      "=== epoch:235, train acc:0.5333333333333333, test acc:0.4304 ===\n",
      "train loss:1.4873622959462671\n",
      "train loss:1.5265848230461976\n",
      "train loss:1.4482816259093436\n",
      "=== epoch:236, train acc:0.5433333333333333, test acc:0.4387 ===\n",
      "train loss:1.5380803828102714\n",
      "train loss:1.4451062824438066\n",
      "train loss:1.398051404882746\n",
      "=== epoch:237, train acc:0.5533333333333333, test acc:0.4451 ===\n",
      "train loss:1.4623477354077625\n",
      "train loss:1.4693145656464823\n",
      "train loss:1.369682914718996\n",
      "=== epoch:238, train acc:0.5466666666666666, test acc:0.4406 ===\n",
      "train loss:1.458357053329735\n",
      "train loss:1.5153295248121272\n",
      "train loss:1.536792909619378\n",
      "=== epoch:239, train acc:0.5433333333333333, test acc:0.4397 ===\n",
      "train loss:1.4919098224954885\n",
      "train loss:1.4818791050200988\n",
      "train loss:1.4341805497384543\n",
      "=== epoch:240, train acc:0.5466666666666666, test acc:0.4387 ===\n",
      "train loss:1.4053367974546085\n",
      "train loss:1.483544926850577\n",
      "train loss:1.4825676722312473\n",
      "=== epoch:241, train acc:0.55, test acc:0.4359 ===\n",
      "train loss:1.4120482540484591\n",
      "train loss:1.5145429681480485\n",
      "train loss:1.3760574061648054\n",
      "=== epoch:242, train acc:0.55, test acc:0.4397 ===\n",
      "train loss:1.4271396370426843\n",
      "train loss:1.3975367369666554\n",
      "train loss:1.4768171726658008\n",
      "=== epoch:243, train acc:0.5433333333333333, test acc:0.4305 ===\n",
      "train loss:1.4980149862544656\n",
      "train loss:1.4209223707966003\n",
      "train loss:1.3474588987989748\n",
      "=== epoch:244, train acc:0.54, test acc:0.4345 ===\n",
      "train loss:1.354013962189772\n",
      "train loss:1.423248876040954\n",
      "train loss:1.3441529277231659\n",
      "=== epoch:245, train acc:0.5533333333333333, test acc:0.4435 ===\n",
      "train loss:1.5349255112494848\n",
      "train loss:1.4550122507513947\n",
      "train loss:1.3085011095159576\n",
      "=== epoch:246, train acc:0.5533333333333333, test acc:0.4466 ===\n",
      "train loss:1.4346218221298679\n",
      "train loss:1.5094114688880749\n",
      "train loss:1.4415849011132562\n",
      "=== epoch:247, train acc:0.56, test acc:0.4473 ===\n",
      "train loss:1.4103232932110044\n",
      "train loss:1.2278495961225673\n",
      "train loss:1.4175291589793735\n",
      "=== epoch:248, train acc:0.56, test acc:0.443 ===\n",
      "train loss:1.4782906748075262\n",
      "train loss:1.4472421165080975\n",
      "train loss:1.3505891361439983\n",
      "=== epoch:249, train acc:0.56, test acc:0.445 ===\n",
      "train loss:1.4408899343097072\n",
      "train loss:1.4499371975702247\n",
      "train loss:1.4662577631285658\n",
      "=== epoch:250, train acc:0.5566666666666666, test acc:0.4444 ===\n",
      "train loss:1.4233607885540027\n",
      "train loss:1.4993578572141126\n",
      "train loss:1.3642361956230453\n",
      "=== epoch:251, train acc:0.5566666666666666, test acc:0.4423 ===\n",
      "train loss:1.514985357925007\n",
      "train loss:1.4045273342788591\n",
      "train loss:1.2654488732851914\n",
      "=== epoch:252, train acc:0.57, test acc:0.4481 ===\n",
      "train loss:1.3747797307927712\n",
      "train loss:1.4228921189979602\n",
      "train loss:1.355382854701864\n",
      "=== epoch:253, train acc:0.5733333333333334, test acc:0.4445 ===\n",
      "train loss:1.3835761457567353\n",
      "train loss:1.367654680421294\n",
      "train loss:1.3425998986918208\n",
      "=== epoch:254, train acc:0.5766666666666667, test acc:0.4508 ===\n",
      "train loss:1.4299266020021926\n",
      "train loss:1.3237087287394749\n",
      "train loss:1.409247354040728\n",
      "=== epoch:255, train acc:0.5666666666666667, test acc:0.451 ===\n",
      "train loss:1.4189071220672518\n",
      "train loss:1.3920333401619858\n",
      "train loss:1.4191552160630894\n",
      "=== epoch:256, train acc:0.57, test acc:0.4508 ===\n",
      "train loss:1.3540311431754397\n",
      "train loss:1.3328574447771635\n",
      "train loss:1.3257405952563743\n",
      "=== epoch:257, train acc:0.5666666666666667, test acc:0.4502 ===\n",
      "train loss:1.345645158715663\n",
      "train loss:1.3845279427680781\n",
      "train loss:1.4064598713451968\n",
      "=== epoch:258, train acc:0.57, test acc:0.4482 ===\n",
      "train loss:1.3660364424182692\n",
      "train loss:1.4370030461960315\n",
      "train loss:1.4189765206333027\n",
      "=== epoch:259, train acc:0.5766666666666667, test acc:0.4523 ===\n",
      "train loss:1.3930229666583316\n",
      "train loss:1.2809183805316002\n",
      "train loss:1.4322021003395644\n",
      "=== epoch:260, train acc:0.56, test acc:0.4405 ===\n",
      "train loss:1.3576824539859709\n",
      "train loss:1.386028228869192\n",
      "train loss:1.341307714582981\n",
      "=== epoch:261, train acc:0.5733333333333334, test acc:0.4392 ===\n",
      "train loss:1.3006675202482751\n",
      "train loss:1.3413798273071027\n",
      "train loss:1.3350084968610743\n",
      "=== epoch:262, train acc:0.5733333333333334, test acc:0.4379 ===\n",
      "train loss:1.3228071980953675\n",
      "train loss:1.3560496866984584\n",
      "train loss:1.356579382720513\n",
      "=== epoch:263, train acc:0.5766666666666667, test acc:0.444 ===\n",
      "train loss:1.4303082995908987\n",
      "train loss:1.3539616520920108\n",
      "train loss:1.2934461834562538\n",
      "=== epoch:264, train acc:0.5833333333333334, test acc:0.4433 ===\n",
      "train loss:1.4260234011597686\n",
      "train loss:1.3461167453407847\n",
      "train loss:1.348269292298842\n",
      "=== epoch:265, train acc:0.59, test acc:0.4445 ===\n",
      "train loss:1.3555810638471015\n",
      "train loss:1.3306730955388477\n",
      "train loss:1.3064889936203157\n",
      "=== epoch:266, train acc:0.6033333333333334, test acc:0.4522 ===\n",
      "train loss:1.4104485757671228\n",
      "train loss:1.2964498003013305\n",
      "train loss:1.328947329250144\n",
      "=== epoch:267, train acc:0.6, test acc:0.4497 ===\n",
      "train loss:1.4621086341836877\n",
      "train loss:1.239006072198999\n",
      "train loss:1.2116412668585985\n",
      "=== epoch:268, train acc:0.59, test acc:0.4521 ===\n",
      "train loss:1.2556152058155106\n",
      "train loss:1.3345926257020224\n",
      "train loss:1.161598066916306\n",
      "=== epoch:269, train acc:0.6066666666666667, test acc:0.4594 ===\n",
      "train loss:1.3194138644907527\n",
      "train loss:1.3922406698298686\n",
      "train loss:1.2337514670479102\n",
      "=== epoch:270, train acc:0.61, test acc:0.4606 ===\n",
      "train loss:1.3725157832120096\n",
      "train loss:1.311619509225089\n",
      "train loss:1.2635455423479964\n",
      "=== epoch:271, train acc:0.6133333333333333, test acc:0.4598 ===\n",
      "train loss:1.2138589016098733\n",
      "train loss:1.3898308179985535\n",
      "train loss:1.3491654184837114\n",
      "=== epoch:272, train acc:0.6266666666666667, test acc:0.4611 ===\n",
      "train loss:1.1980492154888545\n",
      "train loss:1.3348253724689014\n",
      "train loss:1.2317530055489538\n",
      "=== epoch:273, train acc:0.6266666666666667, test acc:0.4613 ===\n",
      "train loss:1.3720538795697783\n",
      "train loss:1.326113722181338\n",
      "train loss:1.145557612470462\n",
      "=== epoch:274, train acc:0.6366666666666667, test acc:0.4655 ===\n",
      "train loss:1.1982311763499407\n",
      "train loss:1.3124735572284905\n",
      "train loss:1.3745438457889305\n",
      "=== epoch:275, train acc:0.63, test acc:0.4618 ===\n",
      "train loss:1.2246322278425479\n",
      "train loss:1.31311710394772\n",
      "train loss:1.2409179606731269\n",
      "=== epoch:276, train acc:0.6333333333333333, test acc:0.4608 ===\n",
      "train loss:1.2321362542945742\n",
      "train loss:1.326814365330919\n",
      "train loss:1.2086189393122824\n",
      "=== epoch:277, train acc:0.6366666666666667, test acc:0.4601 ===\n",
      "train loss:1.2177310433398987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.2957932412512658\n",
      "train loss:1.3076615580314592\n",
      "=== epoch:278, train acc:0.6233333333333333, test acc:0.4575 ===\n",
      "train loss:1.1810773362614266\n",
      "train loss:1.306100744735962\n",
      "train loss:1.2591832403229384\n",
      "=== epoch:279, train acc:0.63, test acc:0.4586 ===\n",
      "train loss:1.29335947345005\n",
      "train loss:1.235419902247858\n",
      "train loss:1.3210588276834516\n",
      "=== epoch:280, train acc:0.6433333333333333, test acc:0.4647 ===\n",
      "train loss:1.2529098436863828\n",
      "train loss:1.2838404243954935\n",
      "train loss:1.2143753248198457\n",
      "=== epoch:281, train acc:0.6466666666666666, test acc:0.4674 ===\n",
      "train loss:1.23459089793353\n",
      "train loss:1.1432404055851741\n",
      "train loss:1.1760352816450794\n",
      "=== epoch:282, train acc:0.6466666666666666, test acc:0.4639 ===\n",
      "train loss:1.162813523441191\n",
      "train loss:1.1579741864776865\n",
      "train loss:1.1164766216470832\n",
      "=== epoch:283, train acc:0.65, test acc:0.4677 ===\n",
      "train loss:1.2868705120429005\n",
      "train loss:1.176388527020254\n",
      "train loss:1.3417883308048388\n",
      "=== epoch:284, train acc:0.6466666666666666, test acc:0.4704 ===\n",
      "train loss:1.2489994375235838\n",
      "train loss:1.1794252204515485\n",
      "train loss:1.2218633822270417\n",
      "=== epoch:285, train acc:0.6533333333333333, test acc:0.4732 ===\n",
      "train loss:1.215567050047038\n",
      "train loss:1.1734341709158036\n",
      "train loss:1.293455636983677\n",
      "=== epoch:286, train acc:0.67, test acc:0.4814 ===\n",
      "train loss:1.2793486377245156\n",
      "train loss:1.1966498976068356\n",
      "train loss:1.1371346392182118\n",
      "=== epoch:287, train acc:0.6666666666666666, test acc:0.4832 ===\n",
      "train loss:1.2325427031593268\n",
      "train loss:1.342874984291893\n",
      "train loss:1.327703503781107\n",
      "=== epoch:288, train acc:0.6733333333333333, test acc:0.4864 ===\n",
      "train loss:1.094033357878249\n",
      "train loss:1.3389183862006022\n",
      "train loss:1.2074650180772364\n",
      "=== epoch:289, train acc:0.6633333333333333, test acc:0.4833 ===\n",
      "train loss:1.1930965479168776\n",
      "train loss:1.236638496312176\n",
      "train loss:1.0581749215897331\n",
      "=== epoch:290, train acc:0.6666666666666666, test acc:0.4901 ===\n",
      "train loss:1.0887398562731507\n",
      "train loss:1.2782683211702508\n",
      "train loss:1.1798417373588326\n",
      "=== epoch:291, train acc:0.6666666666666666, test acc:0.4916 ===\n",
      "train loss:1.0989757982311679\n",
      "train loss:1.1598871777443491\n",
      "train loss:1.2362214825099236\n",
      "=== epoch:292, train acc:0.6833333333333333, test acc:0.4863 ===\n",
      "train loss:1.2761719121679362\n",
      "train loss:1.2062683076482452\n",
      "train loss:1.2239942609653756\n",
      "=== epoch:293, train acc:0.68, test acc:0.4891 ===\n",
      "train loss:1.1436199865590304\n",
      "train loss:1.1598698452692482\n",
      "train loss:1.1339661063987012\n",
      "=== epoch:294, train acc:0.68, test acc:0.4913 ===\n",
      "train loss:1.1692174712349839\n",
      "train loss:1.2567965206218785\n",
      "train loss:1.1850800446403082\n",
      "=== epoch:295, train acc:0.68, test acc:0.4992 ===\n",
      "train loss:1.2241203977158779\n",
      "train loss:1.206406090007762\n",
      "train loss:1.1633597036437713\n",
      "=== epoch:296, train acc:0.68, test acc:0.5008 ===\n",
      "train loss:1.1140645902358\n",
      "train loss:1.1078850239827132\n",
      "train loss:1.2375484096124378\n",
      "=== epoch:297, train acc:0.6766666666666666, test acc:0.4999 ===\n",
      "train loss:1.116782405458574\n",
      "train loss:0.9694381919137887\n",
      "train loss:1.283812614018745\n",
      "=== epoch:298, train acc:0.6766666666666666, test acc:0.4968 ===\n",
      "train loss:1.1666719695416028\n",
      "train loss:1.1514190368101775\n",
      "train loss:1.1455354247498004\n",
      "=== epoch:299, train acc:0.6833333333333333, test acc:0.5038 ===\n",
      "train loss:1.2078528753950701\n",
      "train loss:1.27445551442622\n",
      "train loss:1.1335228091844105\n",
      "=== epoch:300, train acc:0.69, test acc:0.5144 ===\n",
      "train loss:1.0330981952410567\n",
      "train loss:1.165811145105465\n",
      "train loss:1.1295163991986277\n",
      "=== epoch:301, train acc:0.6866666666666666, test acc:0.5099 ===\n",
      "train loss:1.161432912921899\n",
      "train loss:1.1382178476196352\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5116\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 为了再现过拟合，减少学习数据\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 设定是否使用Dropuout，以及比例 ========================\n",
    "use_dropout = True  # 不使用Dropout的情况下为False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
    "\n",
    "# 绘制图形==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7eee94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
